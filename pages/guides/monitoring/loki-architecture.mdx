---
image: https://raw.githubusercontent.com/devops-journey-uz/assets/main/images/article/loki-setup/banner.jpg
description: "Grafana Loki Arxitekturasi"
---

import { Callout } from "nextra/components";

# Grafana Loki Arxitekturasi

![loki](https://raw.githubusercontent.com/devops-journey-uz/assets/main/images/article/loki-setup/banner.jpg)

## Kirish
Markazlashgan loglarni boshqarish va tahlil qilish hozirgi kunda murakkab tizimlar va mikroservicelar arxitekturalari uchun muhim ahamiyat kasb etadi. 

[**Grafana Loki**](https://github.com/grafana/loki) - bu loglarni saqlash, indekslash va qidirish(search) uchun mo'ljallangan kengaytiriladigan, high-performancega ega tizimdir. Grafana tomonidan ishlab chiqilgan Loki o'zining soddaligi, samaradorligi va Grafana bilan integratsiyalashganligi bilan ajralib turadi.
Grafana Loki arxitekturasi zamonaviy, distributed systemlar ehtiyojlarini qondirish uchun moslashtirilgan. Uning dizayni scalability, high availability va soddalikni ta'kidlab, uni ko'plab **DevOps** va **SRE** jamoalari uchun asosiy tanlovga aylantiradi. Ushbu qo'llanmada biz Grafana Loki Architecture va uning tarkibiy qismlari haqida batafsil ma'lumotga ega bo'lamiz. Kompaniyaning distributed environmentda turli xil tizim resurslaridan loglarni saqlash va boshqarish juda qiyin vazifadir.Ushbu vazifani soddalashtirish uchun **log aggregation**(loglarni yig'ish) deb ataladigan kontseptsiya kiritilgan bo'lib, u turli tizim resurslaridan loglarni to'playdi va boshqaradi.

[**Grafana Loki**](https://github.com/grafana/loki) open-source loglarni yig'ish tizimi bo'lib, uning vazifasi loglarni yig'ish(collect), saqlash(store) va so'rashdir(query).
Grafana Loki logni compress qilib chiqaradi va loglarni **chunk**(bo'lak)larga bo'lib saqlaydi va ularni fayl tizimlarida yoki AWS S3 kabi backend storageda saqlaydi. **Chunk** - bu log hajmiga asoslangan log yozuvlarini o'z ichiga olgan compress qilingan fayl, shuning uchun chunk o'lchami o'zining o'lcham chegarasiga yetganda, u logni boshqa chunkda saqlaydi.
Qachonki chunk saqlangan bo'lsa, u har bir chunk uchun indeks yaratadi. Indeks logning mazmunini o'z ichiga olmaydi, u faqat timestamplarni, chunkning teglarini va chunkning joylashuvini o'z ichiga oladi. Loglarni default saqlash muddati 24 soat, minimal muddat 1 soat va maksimal 30 kungacha uzaytirilishi mumkin. Loki gorizontal ravishda o'lchaydi va **LogQL** so'rov tiliga(query language) ega.

## Grafana Loki Arxitekturasi

Quyidagi animatsiyali arxitekturada Grafana Loki arxitekturasi, shuningdek, uning loglarni qanday yig'ish(collect) jarayoni ko'rsatilgan.

![loki](https://raw.githubusercontent.com/devops-journey-uz/assets/main/images/article/loki-setup/architecture.gif)


Keling, Grafana Loki Logging qanday ishlashini ko'rib chiqaylik. Rasmda Grafana Loki loglarni qanday to'plashi(collect), saqlashi(store), so'rovlari(query) va vizualizatsiyasi ko'rsatilgan. 

* Grafana Loki-da uning agenti fayllar, konteynerlar, podlar, applicationlar va systems journallaridan loglarni yig'ish uchun javobgardir.
* Loki loglarni yig'ish uchun log-collecting agentidan foydalanadi. Agar siz Kubernetes-da Loki-dan foydalansangiz, agent daemon set sifatida deploy qilinadi, chunki bizga klasterning har bir mavjud nodedan loglar kerak bo'ladi.
* **Promtail** - bu arxitekturada ishlatiladigan agent, Promtail har bir mavjud logni to'playdi va keyin xotirani tejash uchun loglarni filtrlaydi va compress qilib siqadi.
* Loglar compress qilingandan so'ng, u loglar uchun label beradi va uni Loki-ga yuboradi.
* Promtail collecting agentdan loglarni olgandan so'ng, Loki har bir logni saqlash joyini tejash va samarali qidirish uchun log messagelarini bitta faylda to'playdigan **chunk** sifatida saqlaydi.
* Shuningdek, u chunkga label va timestamp beradi. Qachonki chunk saqlangan bo'lsa, u har bir chunk uchun timestamp, labeli va chunkning joylashuvini o'z ichiga olgan indeks yaratadi.
* Loki loglarni **LogQL** query languagedan foydalangan holda so'raydi, LogQL biz tanlagan label va valuelar bo'yicha loglarni filtrlash, aggregatlari va tahlil qilish imkonini beradi.
* Loki-ni Grafana-ga qo'shish orqali siz so'ralgan loglarni tasavvur qilishingiz yoki **CLI**-dan loglarni so'rash uchun **LogCLI**-dan foydalanishingiz mumkin.

Qisqa qilib aytganda:

Promtail serverlardan loglarni o'qib label va timestamp qo'yib lokiga HTTP orqali stream qilib jo'natadi, k8s uchun label quyidagicha.

```bash
{namespace="prod", pod="my-app-123", container="app-container"}
```
Loki loglarni promtaildan olib label va timestampdan foydalanib key-value indexlaydi va loglarni chunklar(bo'laklar)ga bo'lib loki server file systemida yoki S3 bucket(Amazon S3, Google Cloud Storage, yoki MinIO)da saqlaydi. Chunklar ma'lum bir vaqt oralig'idagi loglar hisoblanadi masalan 2-minut. Grafana lokidan loglarni LogQL query language orqali so'rovlar berib vizualizatsiya qilib dashboarda ko'rsatadi.

## Grafana Loki Componentlari

Grafana Loki **promtail, distributor, ingester, querier(so'rovchi), ruler, query frontend** va **Grafana** kabi komponentlardan iborat. Keling, ushbu tarkibiy qismlarni ko'rib chiqaylik

### Promtail

**Promtail** Loki uchun logging agent vazifasini bajaradigan muhim komponent hisoblanadi. Uning vazifasi tizimdagi har bir logni yig'ish, unga label qo'yish va Loki-ga yuborishdir. Loki local log fayllari va system journaldan loglarni to'playdi. Loglarni yig'moqchi bo'lgan har bir tizimga Promtailni o'rnatishingiz kerak, xuddi shunday, agar siz Kubernenets-da Loki-dan foydalansangiz, Promtail-ni har bir nodega **demonset** sifatida deploy qilishingiz kerak.

### Distributor

Distributor Loki tizimining bir qismi bo'lib, loglarni qabul qiladi va ularni boshqa komponentlarga (ingester) tarqatadi. Distributor **HTTP** orqali kelayotgan loglarni qabul qiladi. Promtail yoki boshqa log yig'uvchi agentlar loglarni distributorga yuboradi. Distributor kelgan loglarni tekshiradi va ularda to'g'ri label va timestamp mavjudligini tasdiqlaydi. Distributor loglarni hashing algoritmi yordamida hash qiladi va ularni ingester nodelariga tarqatadi. Hashing algoritmi loglarni ma'lum bir ingester nodega yuborilishini aniqlaydi, bu esa loglarning bir xil nodelarda qayta ishlanishini ta'minlaydi. Bu jarayon orqali loglar qayta ishlanish va saqlanish uchun ingester nodelariga o'tadi.

### Ingester

Ingester nodelari loglarni qabul qiladi, qayta ishlaydi va saqlaydi. Ingester quyidagi jarayonlarni amalga oshiradi. Ingester distributor kelgan loglarni qabul qiladi. Ingester loglarni label va timestamp asosida indekslaydi va ularni **chunk**'larga bo'ladi. Har bir chunk ma'lum bir vaqt oralig'iga tegishli loglarni o'z ichiga oladi. Chunk'lar kompressiya qilinadi va storage systemlariga (masalan, Amazon S3, Google Cloud Storage, yoki MinIO) yuboriladi.

### Ruler

Ruler komponenti rulelarni(qoidalar) bajarish(execute) va alertlarni generatsiya qilish uchun ishlatiladi. Bu komponent **Prometheus**'ning **Alertmanager**'iga o'xshash tarzda ishlaydi. Ruler uchun qoidalar (rules) yoziladi, bu rulelar loglarni tahlil qilish va ma'lum shartlar bajarilganda alertlarni yaratish uchun ishlatiladi. Ruler rulelarni belgilangan intervalda bajaradi va loglarni qidiradi. Agar rule bajarilsa, ya'ni shartlar to'g'ri kelsa, alert yaratadi. Agar rule shartlari bajarilsa, Ruler alert yaratadi va bu alert Alertmanager yoki boshqa alert tizimlariga yuboriladi.

### Querier

Querier komponenti loglarni qidirish va search querielarini qayta ishlash uchun javobgar. Grafana yoki boshqa search interfacelaridan kelgan search querielarini qabul qiladi. Querier index ma'lumotlaridan foydalanib, search querielariga mos keladigan loglarni topadi. Querier kerakli chunk'larni topadi va loglarnni qayta ishlaydi keyin Qidiruv natijalari Grafana yoki boshqa search interfacelariga qaytariladi.

### Query Frontend

Query Frontend komponenti search querielarini boshqarish, optimallashtirish va kengaytirish uchun ishlatiladi. Bu komponent querielarni parallel qayta ishlash va kechiktirilgan natijalarni qaytarish orqali search processeslarini tezlashtiradi. Query Frontend userlardan kelgan search querielarini qabul qiladi va katta querielarni kichik bo'laklarga bo'ladi va ularni parallel qayta ishlash uchun querier nodelariga yuboradi. Kichik chunklardan kelgan natijalarni yig'adi va birlashtiradi va natijalarni keshlash orqali tezkor response qaytaradi va qayta-qayta bajariladigan so'rovlarni tezlashtiradi.

### Grafana

Grafana Loki bilan integratsiyalashgan holda loglarni qidirish va vizualizatsiya qilish jarayonini soddalashtiradi. Grafana interfeysida Loki data source sifatida qo'shiladi. Bu jarayon Loki serverining URL manzilini va autentifikatsiya ma'lumotlarini kiritishni o'z ichiga oladi. Userlar **LogQL** yordamida querilarni yozadi. LogQL Prometheus Query Language (PromQL) ga o'xshash bo'lib, loglarni label va timestamp asosida qidirishga imkon beradi.

### Log Storage

Loki loglarni so'rash va qabul qilish samaradorligini oshirish uchun log ma'lumotlarini saqlaydi. U log ma'lumotlarini chunklarga bo'lib compress qilib, ularni vaqt bo'yicha tartibga soladi va unga label va timestamp beradi. Keyin u har bir chunk uchun key-value formatida indeks yaratadi, ularning log yozuvlari chunk timestampi va labeli bilan. Chunklar va indekslar turli xil backend object storagelarida yoki fayl tizimlarida saqlanishi mumkin. Chunklar saqlanganidan so'ng, u ma'lumotlar uchun saqlash muddatini yaratadi va saqlash muddatiga qarab avtomatik ravishda o'chiriladi. Agar siz fayl tizimidan saqlash sifatida foydalanayotgan bo'lsangiz, chunklar va indekslar uchun default saqlash pathlari `/var/lib/loki/chunks` va `/var/lib/loki/index` hisoblanadi.


## Lokida chunklar va indexlar saqlanishi

Misol tariqasida, timestamp, HTTP request method, URL manzili va response codeni o'z ichiga olgan logni yaratadigan web-serverdan foydalanayotganingizni tasavvur qiling.

Log yozuvlarining har bir to'plami quyidagi JSON formati kabi chunklarga solishtiriladi

```json
{
  "timestamp": "2023-11-20T1:02:33.456Z",
  "labels": {
    "method": "GET",
    "url": "/products",
    "status": 200
  },
  "entry": "Request received for /products, responded with 200 OK"
}
```

Chunk fayl nomi ushbu formatda bo'ladi

```txt
2023-11-20T1-00-00.000Z-2023-11-20T1-15-00.000Z.chunk
```

Nomidan ko'rinib turibdiki, chunk 2023-yil 20-noyabrdan ertalab soat 1 dan 1:15 gacha loglarni o'z ichiga oladi. Chunk yaratilgandan so'ng, har bir chunk uchun indeks yaratiladi, indeks parcha fayli va log yozuvlari haqidagi ma'lumotlarni quyida keltirilgan key-value formatida saqlaydi.

```json
{
  "2023-11-20T1:02:33.456Z": {
    "chunk": "2023-11-20T1-00-00.000Z-2023-11-20T1-15-00.000Z.chunk",
    "labels": {
      "method": "GET",
      "url": "/products",
      "status": 200
    }
  }
}
```

Yuqoridagi misol indeks faylida ko'rsatilganidek, u faqat fayl nomi, timestamp va labelini saqlaydi, u log xabarini saqlamaydi.


<Callout type="info" emoji="">

Qo'shimcha Resurslar

 * [**Serverlarni monitoring qilish yoxud Grafana, Prometheus, Node Exporter o'rnatish va sozlash**](https://devops-journey.uz/guides/monitoring/gnp-monitoring)
 * [**ELK Stackga kirish**](https://devops-journey.uz/tutorials/article/elk-stack)
 * [**ELK Stack Cluster o'rnatish va sozlash**](https://devops-journey.uz/tutorials/article/elk-setup)
 * [**APM Server Sozlash**](https://devops-journey.uz/tutorials/article/apm-server-sozlash)
 * [**PostgreSQL Monitoring**](https://devops-journey.uz/guides/database/postgres-monitoring)

 Qo'llanma uchun foydalanilgan resurslar
 * [**Grafana Loki Architecture: A Comprehensive Guide**](https://devopscube.com/grafana-loki-architecture/)

**Sana:** 2024.06.24(2024-yil 24-iyun)

**Oxirgi yangilanish:** 2024.06.24(2024-yil 24-iyun)

**Muallif: Otabek Ismoilov**

| [Telegram](https://t.me/Otabek_Ismoilov) | [GitHub](https://github.com/ismoilovdevml) | [LinkedIn](https://www.linkedin.com/in/otabek-ismoilov/) |
| - | - | - |

</Callout>
